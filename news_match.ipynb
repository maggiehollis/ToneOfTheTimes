{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b85f8ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Looking for .env file and loading it\n",
    "load_dotenv() \n",
    "\n",
    "nyt_api = os.getenv(\"NYT_ID\")\n",
    "guardian_api =  os.getenv(\"GUARDIAN_ID\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc727e3",
   "metadata": {},
   "source": [
    "# News Collection\n",
    "Pull today's headline from the NYT API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315a7be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top NYT article: 100 Days of Solitude: Trump and the Retreat of America: President Trumpâ€™s approach to foreign policy in his second term has been transactional, unpredictable and exploitative. Allies and enemies alike are beginning to adapt.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "URL = f'https://api.nytimes.com/svc/topstories/v2/home.json?api-key={nyt_api}'\n",
    "\n",
    "response = requests.get(URL)\n",
    "\n",
    "nyt_articles = []\n",
    "\n",
    "\n",
    "if response.status_code == 200:\n",
    "    data = response.json()\n",
    "    if data['results']:\n",
    "        # Assume the first article is the main front-page article\n",
    "        for article in data['results']:\n",
    "            nyt_articles.append(article['title'] + \": \" + article['abstract'])\n",
    "    else:\n",
    "        print(\"No articles found.\")\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "    \n",
    "# curr_article = nyt_articles[6]\n",
    "# print(\"Top NYT article:\", curr_article)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "811fa6eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top Guardian article: White House opens inquiry into Chicago school program aimed at helping Black students: Education department says school program to improve Black academic performance violates 1964 Civil Rights Act\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Parameters\n",
    "SECTION = 'us-news'\n",
    "DATE = datetime.now().strftime('%Y-%m-%d')\n",
    "URL = 'https://content.guardianapis.com/search'\n",
    "NUM_ARTICLES = 8\n",
    "\n",
    "params = {\n",
    "    'section': SECTION,\n",
    "    'from-date': DATE,\n",
    "    'to-date': DATE,\n",
    "    'order-by': 'newest',\n",
    "    'page-size': NUM_ARTICLES,\n",
    "    'show-fields': 'trailText',\n",
    "    'api-key': guardian_api\n",
    "}\n",
    "\n",
    "guardian_articles = []\n",
    "\n",
    "try:\n",
    "    response = requests.get(URL, params=params)\n",
    "    response.raise_for_status()\n",
    "    data = response.json()\n",
    "\n",
    "    if data.get('response', {}).get('status') == 'ok' and data['response']['results']:\n",
    "        articles = data['response']['results']\n",
    "        for idx, article in enumerate(articles, start=1):\n",
    "            title = article.get('webTitle', 'No Title')\n",
    "            abstract = article.get('fields', {}).get('trailText', 'No Abstract')\n",
    "            guardian_articles.append(title + \": \" + abstract)\n",
    "    else:\n",
    "        print(\"No articles found for today.\")\n",
    "\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"An error occurred: {e}\")\n",
    "\n",
    "curr_article = guardian_articles[1]\n",
    "print(\"Top Guardian article:\", curr_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5056ed26",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "# NLP Analysis of News\n",
    "Calculate sentiment of news articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bedbefb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "model_name = \"SamLowe/roberta-base-go_emotions\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "\n",
    "def get_emotions(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        logits = model(**inputs).logits\n",
    "    probs = F.softmax(logits, dim=1)[0]\n",
    "    labels = model.config.id2label\n",
    "    return {labels[i]: float(probs[i]) for i in range(len(probs))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05b49a37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NYT Headline Sentiment: {'neg': 0.109, 'neu': 0.724, 'pos': 0.168, 'compound': 0.2023}\n",
      "NYT Headline Emotions: {'admiration': 0.00013471378770191222, 'amusement': 0.00015377420641016215, 'anger': 0.0005468361196108162, 'annoyance': 0.004671675618737936, 'approval': 0.003305030521005392, 'caring': 0.00022645157878287137, 'confusion': 0.0004121381207369268, 'curiosity': 0.00045816448982805014, 'desire': 0.00018865620950236917, 'disappointment': 0.0018068073550239205, 'disapproval': 0.001724222325719893, 'disgust': 0.0006506206700578332, 'embarrassment': 0.0004710674111265689, 'excitement': 5.2985102229285985e-05, 'fear': 0.0001318247668677941, 'gratitude': 4.4513715693028644e-05, 'grief': 8.407147834077477e-05, 'joy': 5.984858944430016e-05, 'love': 7.615025242557749e-05, 'nervousness': 7.241293496917933e-05, 'optimism': 0.00022064350196160376, 'pride': 3.0131264793453738e-05, 'realization': 0.0022846886422485113, 'relief': 4.5873417548136786e-05, 'remorse': 0.00018521983292885125, 'sadness': 0.0009374067303724587, 'surprise': 6.170465348986909e-05, 'neutral': 0.9809624552726746}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/maggiehollis/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/maggiehollis/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/maggiehollis/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "\n",
    "# Setup NLTK\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Disable TensorFlow in HuggingFace Transformers (optional for PyTorch-only)\n",
    "os.environ[\"TRANSFORMERS_NO_TF\"] = \"1\"\n",
    "\n",
    "# Stopwords and Sentiment\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "sentiment_analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "# --- NYT Headline ---\n",
    "tokenized_nyt = word_tokenize(curr_article)\n",
    "filtered_nyt = [word.lower() for word in tokenized_nyt if word.isalnum() and word.lower() not in stop_words]\n",
    "\n",
    "nyt_text = ' '.join(filtered_nyt)\n",
    "\n",
    "# VADER Sentiment\n",
    "news_sentiment_nyt = sentiment_analyzer.polarity_scores(nyt_text)\n",
    "print(\"NYT Headline Sentiment:\", news_sentiment_nyt)\n",
    "\n",
    "# Emotion Detection\n",
    "emotions_nyt = get_emotions(curr_article)  # Truncate if needed\n",
    "print(\"NYT Headline Emotions:\", emotions_nyt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25ccfd61",
   "metadata": {},
   "source": [
    "# Song Recs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8e344168",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Matching Song:\n",
      "Artist: Black Label Society\n",
      "Title: Fire It Up\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# === Load and prepare CSV ===\n",
    "df = pd.read_csv(\"song_sentiments_emotions.csv\")\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = [col.strip().lower() for col in df.columns]\n",
    "\n",
    "# Create full DataFrame (with artist and title)\n",
    "df_full = df.copy()\n",
    "\n",
    "# Create vector DataFrame by dropping the first two columns (artist, title)\n",
    "df_vectors = df.iloc[:, 2:]  # assumes first two are metadata\n",
    "\n",
    "# Convert df_vectors to numeric matrix\n",
    "df_matrix = df_vectors.apply(pd.to_numeric, errors='coerce').fillna(0.0).to_numpy()\n",
    "\n",
    "# === Define emotion & sentiment keys (in order) ===\n",
    "emotion_keys = [\n",
    "    'admiration','amusement','anger','annoyance','approval','caring','confusion','curiosity',\n",
    "    'desire','disappointment','disapproval','disgust','embarrassment','excitement','fear',\n",
    "    'gratitude','grief','joy','love','nervousness','neutral','optimism','pride','realization',\n",
    "    'relief','remorse','sadness','surprise'\n",
    "]\n",
    "\n",
    "sentiment_keys = ['negative', 'neutral', 'positive', 'compound']\n",
    "\n",
    "# === Build input_vector from your VADER and emotion outputs ===\n",
    "vader_to_csv = {\n",
    "    'negative': news_sentiment_nyt['neg'],\n",
    "    'neutral': news_sentiment_nyt['neu'],\n",
    "    'positive': news_sentiment_nyt['pos'],\n",
    "    'compound': news_sentiment_nyt['compound']\n",
    "}\n",
    "\n",
    "input_vector = [vader_to_csv[key] for key in sentiment_keys] + [\n",
    "    emotions_nyt.get(key, 0.0) for key in emotion_keys\n",
    "]\n",
    "\n",
    "# === Compute cosine similarity ===\n",
    "similarities = cosine_similarity([input_vector], df_matrix)\n",
    "best_index = np.argmax(similarities)\n",
    "best_match = df_full.iloc[best_index]\n",
    "\n",
    "# === Output ===\n",
    "print(\"Best Matching Song:\")\n",
    "print(\"Artist:\", best_match['artist'])\n",
    "print(\"Title:\", best_match['title'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cc567e4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bigdata2025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
